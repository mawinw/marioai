{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sdjZvStcjU_-",
    "outputId": "c288901b-38be-465a-da82-6ef36501ade3"
   },
   "outputs": [],
   "source": [
    "import sys, time, os, random\n",
    "#%tensorflow_version 1.x\n",
    "import tensorflow\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from collections import deque\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import  GlobalAveragePooling2D, Input, concatenate\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import pydot\n",
    "import pydotplus\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "GhXyuIwujVBd",
    "outputId": "a8a95f89-f00d-4db4-f918-8d7cb857d7ec"
   },
   "outputs": [],
   "source": [
    "state_size = np.array([22,22,1])\n",
    "state_info = 47\n",
    "action_size = 12\n",
    "batch_size = 32\n",
    "n_episodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yWeVO8A8jVBo",
    "outputId": "3ccd9a0c-a0db-4046-aff8-250ca33e37d2"
   },
   "outputs": [],
   "source": [
    "local_dir = 'bu/mawinw/reinforce/'\n",
    "\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27E0yd_ZjVB9"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        \n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.998\n",
    "        self.epsilon_min = 0.1\n",
    "        \n",
    "        self.learning_rate = 0.001\n",
    "        \n",
    "        self.model = self._build_inception_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(32, kernel_size=3, strides=(1,1,1), padding=\"same\", activation='relu', input_shape=state_size, data_format=\"channels_last\"))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation = 'relu'))\n",
    "        model.add(Dense(256, activation = 'relu'))\n",
    "        model.add(Dense(self.action_size, activation = 'linear'))\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "        \n",
    "    def build_two_input_model(self):\n",
    "\n",
    "        # define two sets of inputs\n",
    "        inputA = Input(shape=(state_size,))\n",
    "        inputB = Input(shape=(state_info,))\n",
    "        # the first branch operates on the first input\n",
    "        x = Dense(8, activation=\"relu\")(inputA)\n",
    "        x = Dense(4, activation=\"relu\")(x)\n",
    "        x = Model(inputs=inputA, outputs=x)\n",
    "        # the second branch opreates on the second input\n",
    "        # combine the output of the two branches\n",
    "        combined = concatenate([x.output, y.output])\n",
    "        # apply a FC layer and then a regression prediction on the\n",
    "        # combined outputs\n",
    "        z = Dense(2, activation=\"relu\")(combined)\n",
    "        z = Dense(1, activation=\"linear\")(z)\n",
    "        # our model will accept the inputs of the two branches and\n",
    "        # then output a single value\n",
    "        model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "        \n",
    "    def build_simple_conv2d(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=1, strides=(1,1), padding=\"same\", activation='relu', input_shape=state_size, data_format=\"channels_last\"))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=(1,1), padding=\"same\", activation='relu'))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=(1,1), padding=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=(1,1), padding=\"same\", activation='relu'))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=(1,1), padding=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation = 'relu'))\n",
    "        model.add(Dense(128, activation = 'relu'))\n",
    "        model.add(Dense(self.action_size, activation = 'linear'))\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "        \n",
    "\n",
    "    def _build_inception_model(self):\n",
    "\n",
    "\n",
    "        #model = InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "        # create the base pre-trained model\n",
    "        #base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=state_size, pooling=None, classes=100)\n",
    "        \n",
    "        inputA = Input(shape=(22,22,1))\n",
    "        \n",
    "        # add a global spatial average pooling layer\n",
    "\n",
    "        \n",
    "        tower_1 = Conv2D(32, (3, 3), padding='same', activation='relu')(inputA)\n",
    "        tower_2 = Conv2D(32, (5, 5), padding='same', activation='relu')(inputA)\n",
    "        tower_3 = Conv2D(32, (7, 7), padding='same', activation='relu')(inputA)\n",
    "        \n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3])\n",
    "        output = MaxPooling2D((3, 3), strides=(1, 1))(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # let's add a fully-connected layer\n",
    "        output = Flatten()(output)\n",
    "        x = Dense(16, activation='relu')(output)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Model(inputA, outputs=x)\n",
    "        \n",
    "        inputB = Input(shape=(state_info,))\n",
    "        y = Dense(16, activation=\"relu\")(inputB)\n",
    "        y = Dense(16, activation=\"relu\")(y)\n",
    "        y = Dense(16, activation=\"relu\")(y)\n",
    "        y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "        combined = concatenate([x.output, y.output])\n",
    "\n",
    "        z = Dense(32, activation=\"relu\")(combined)\n",
    "        z = Dense(32, activation=\"linear\")(z)\n",
    "\n",
    "        # and a logistic layer -- let's say we have self.action_size classes\n",
    "        predictions = Dense(self.action_size, activation='softmax')(z)\n",
    "\n",
    "\n",
    "        # this is the model we will train\n",
    "        model = Model(inputs=[inputA, inputB], outputs=predictions)\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        #act_values = self.model.predict(np.array([state]))\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values)\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        \n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "            \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(local_dir+name)\n",
    "        \n",
    "    def save(self, name):\n",
    "        self.model.save_weights(local_dir+name)\n",
    "        \n",
    "    def save_model_formatting(self, name):\n",
    "        self.model.save_weights(local_dir+name+'.hdf5')\n",
    "        self.model.save(local_dir+name+'.h5')\n",
    "        model_json = self.model.to_json()\n",
    "        with open(local_dir+name+'.json', \"w\") as json_file:\n",
    "            json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "iFX8CsPLjVEG",
    "outputId": "a3fbfe88-71ca-46b9-bac4-0018b714a021"
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EB44ttcFcXO"
   },
   "outputs": [],
   "source": [
    "#agent.model.output\n",
    "#plot_model(agent.model, to_file='inception_with_info.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K39wwXrd1hB2"
   },
   "outputs": [],
   "source": [
    "fname = \"inception_with_info.hdf5\"\n",
    "agent.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 5s - loss: 69.9282\n",
      "Epoch 2/2\n",
      " - 5s - loss: 69.9282\n",
      "Epoch 1/2\n",
      " - 5s - loss: 90.6006\n",
      "Epoch 2/2\n",
      " - 6s - loss: 90.6006\n",
      "Epoch 1/2\n",
      " - 5s - loss: 69.8916\n",
      "Epoch 2/2\n",
      " - 7s - loss: 69.8916\n",
      "Epoch 1/2\n",
      " - 6s - loss: 90.4957\n",
      "Epoch 2/2\n",
      " - 6s - loss: 90.4957\n",
      "Epoch 1/2\n",
      " - 6s - loss: 69.7377\n",
      "Epoch 2/2\n",
      " - 6s - loss: 69.7377\n",
      "Epoch 1/2\n",
      " - 6s - loss: 69.8562\n",
      "Epoch 2/2\n",
      " - 5s - loss: 69.8562\n",
      "Epoch 1/2\n",
      " - 6s - loss: 69.2658\n",
      "Epoch 2/2\n",
      " - 7s - loss: 69.2658\n",
      "Epoch 1/2\n",
      " - 5s - loss: 70.0296\n",
      "Epoch 2/2\n",
      " - 5s - loss: 70.0296\n",
      "Epoch 1/2\n",
      " - 5s - loss: 70.0140\n",
      "Epoch 2/2\n",
      " - 5s - loss: 70.0140\n",
      "Epoch 1/2\n",
      " - 6s - loss: 83.7135\n",
      "Epoch 2/2\n",
      " - 6s - loss: 83.7135\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    \n",
    "    csv_location = \".\\\\bu\\\\mawinw\\\\record\\\\Reinforce_Model_Episode_\"+str(i)+\".csv\"\n",
    "    file1 = open(csv_location, 'r') \n",
    "    Lines = file1.readlines() \n",
    "\n",
    "    count = 0\n",
    "    # Strips the newline character \n",
    "    linecount = 0\n",
    "    linestring = \"\"\n",
    "    frames = []\n",
    "    for line in Lines: \n",
    "        line = line.replace('\\n', ' ').replace('\\r', '')\n",
    "        linestring += line\n",
    "        linecount += 1\n",
    "        if(linecount == 43):\n",
    "            linecount = 0\n",
    "            frames.append(linestring)\n",
    "            linestring = \"\"\n",
    "    file1.close()\n",
    "    \n",
    "    states = []\n",
    "    state_infos = []\n",
    "    target_fs = []\n",
    "    for frame in frames:\n",
    "        state, state_info, action, reward, next_state,next_state_info, done = frame.split('|')\n",
    "        \n",
    "        state = np.array(literal_eval(state), dtype=\"float\").reshape(22,22,1)\n",
    "        state_info = np.array([literal_eval(state_info)], dtype=\"float\")\n",
    "        \n",
    "        next_state = np.array([literal_eval(next_state)], dtype=\"float\").reshape(22,22,1)\n",
    "        next_state_info = np.array(literal_eval(next_state_info), dtype=\"float\")\n",
    "        \n",
    "#         agent.model.predict(\n",
    "#     [np.array([state]), \n",
    "#      np.array(literal_eval(state_info), dtype=\"float\").reshape(1,47)]\n",
    "#     )\n",
    "        states.append(state)\n",
    "        state_infos.append(state_info[0])\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + agent.gamma * np.amax(agent.model.predict([np.array([next_state]), next_state_info]))[0]\n",
    "        target_f = agent.model.predict([np.array([state]), state_info])\n",
    "        target_f[0][int(action)] = target\n",
    "        target_fs.append(target_f[0])\n",
    "    agent.model.fit([np.array(states),np.array(state_infos)], [target_fs], epochs=2, verbose=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_model_formatting('inception_with_info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent.model.predict(\n",
    "    [np.array([state]), \n",
    "     np.array(literal_eval(state_info), dtype=\"float\").reshape(1,47)]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "P1 - Mario-Gym.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
